# create a dataframe with the data
data <- data.frame(
yield = c(87.2, 81.8, 88.5, 82.9, 86.6, 83.3, 89.1, 83.8),
nitric_acid_time = factor(rep(c("2 hours", "7 hours"), each = 4)),
stirring_time = factor(rep(c("1/2 hour", "4 hours"), times = 2)),
heel = factor(rep(c("No Heel", "With Heel"), times = 4))
)
# plot the interaction between nitric_acid_time and stirring_time, with heel as the trace variable
interaction.plot(x.factor = data$nitric_acid_time,
trace.factor = data$stirring_time,
response = data$yield,
fun = mean,
type = "b",
legend = FALSE,
ylim = c(80, 90),
xlab = "Nitric Acid Time",
ylab = "Yield",
main = "Interaction Plot: Nitric Acid Time vs Stirring Time")
# plot the interaction between nitric_acid_time and heel, with stirring_time as the trace variable
interaction.plot(x.factor = data$nitric_acid_time,
trace.factor = data$heel,
response = data$yield,
fun = mean,
type = "b",
legend = FALSE,
ylim = c(80, 90),
xlab = "Nitric Acid Time",
ylab = "Yield",
main = "Interaction Plot: Nitric Acid Time vs Heel")
# plot the interaction between stirring_time and heel, with nitric_acid_time as the trace variable
interaction.plot(x.factor = data$stirring_time,
trace.factor = data$heel,
response = data$yield,
fun = mean,
type = "b",
legend = FALSE,
ylim = c(80, 90),
xlab = "Stirring Time",
ylab = "Yield",
main = "Interaction Plot: Stirring Time vs Heel")
# Create a data frame with the given data
nitration <- data.frame(
heel = factor(rep(c("No Heel", "With Heel"), each = 4)),
acid_time = factor(rep(rep(c("2 hours", "7 hours"), each = 2), times = 2)),
stir_time = factor(rep(c("1/2 hour", "4 hours"), times = 4)),
yield = c(87.2, 81.8, 88.5, 82.9, 86.6, 83.3, 89.1, 83.8)
)
nitration
# Calculate the mean yield for each level of time of addition of nitric acid
mean_yield <- tapply(nitration$yield, nitration$acid_time, mean)
# Calculate the main effect of time of addition of nitric acid
main_effect <- mean_yield["7 hours"] - mean_yield["2 hours"]
main_effect
# Fit the linear model with no interaction terms
nitration_lm <- lm(yield ~ heel + acid_time + stir_time, data = nitration)
# Compute the ANOVA table
anova(nitration_lm)
knitr::opts_chunk$set(echo = TRUE)
itrain <- c(187, 116, 125, 80, 72, 188, 105, 154, 40, 148, 172, 200, 17, 135, 144, 146, 114, 143, 164, 96, 61, 34, 24, 141, 36, 44, 124, 112, 58, 99, 110, 39, 82, 171, 149, 69, 78, 59, 189, 83, 102, 37, 25, 111, 140, 2, 87, 92, 163, 91, 97, 22, 47, 28, 27, 104, 76, 4, 145, 166, 126, 10, 168, 169, 67, 170, 14, 175, 12, 1, 23, 108, 151, 64, 50, 57, 51, 46, 119, 90, 41, 31, 191, 38, 186, 98, 49, 138, 183, 130, 117, 150, 180, 121, 9, 128, 93, 88, 95, 115, 13, 167, 198, 122, 107, 156, 60, 66, 5, 56, 113, 127, 71, 157, 8, 196, 73, 199, 21, 133, 195, 68, 131, 94, 109, 35, 33, 62, 53, 120, 84, 129, 26, 136, 29, 19, 162, 185, 11, 48, 74, 139, 100, 106, 32, 63, 160, 184, 118, 103, 174, 70, 152, 43, 192, 193, 20, 178, 158, 15, 79, 89, 3, 173, 75, 147, 81, 101, 134, 85)
ihold <- c(245, 21, 91, 233, 157, 127, 114, 243, 31, 224, 176, 59, 260, 6, 71, 50, 328, 312, 330, 44, 188, 234, 7, 64, 85, 144, 246, 299, 39, 317, 97, 283, 49, 229, 72, 221, 78, 154, 265, 226, 102, 76, 303, 286, 41, 5, 20, 266, 104, 252, 112, 3, 290, 82, 40, 11, 321, 320, 193, 181, 29, 151, 137, 238, 153, 93, 190, 306, 145, 217, 89, 268, 186, 220, 32, 201, 125, 123, 302, 22, 86, 199, 118, 171, 45, 43, 133, 70, 269, 184, 203, 274, 323, 161, 219, 291, 73, 175, 51, 284, 267, 263, 168, 14, 332, 293, 53, 272, 54, 63, 126, 159, 83, 84, 327, 131, 249, 109, 198, 18, 183, 208, 202, 121, 15, 227, 288, 156, 129, 26, 142, 182, 322, 23, 250, 163, 259, 140, 200, 210, 47, 270, 106, 158, 285, 19, 139, 209, 61, 240, 101, 24, 81, 130, 79, 275, 197, 92, 1, 213, 146, 307, 324, 315, 122, 136, 165, 107, 258, 257, 77, 230, 80, 225, 60, 108, 33, 174, 180, 308, 124, 75, 35, 271, 46, 48, 111, 143, 119, 273, 2, 326, 206, 331, 277, 189, 100, 169, 287, 55)
library(MASS)
data(Pima.tr)
mytrain=Pima.tr[itrain,] #train data
data(Pima.te)
myhold=Pima.te[ihold,] #hold data
# Fit logistic regression model with all 7 explanatory variables
model1 <- glm(type ~ npreg + glu + bp + skin + bmi + ped + age, data = mytrain, family = "binomial")
# Fit logistic regression model with 4 explanatory variables
model2 <- glm(type ~ glu + bmi + ped + age, data = mytrain, family = "binomial")
# Apply models to holdout dataset and get predicted probabilities
myhold$pred_prob_model1 <- predict(model1, newdata = myhold, type = "response")
myhold$pred_prob_model2 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on predicted probabilities
myhold$pred_class_model1 <- ifelse(myhold$pred_prob_model1 >= 0.5, "Yes", "No")
myhold$pred_class_model2 <- ifelse(myhold$pred_prob_model2 >= 0.5, "Yes", "No")
itrain <- c(187, 116, 125, 80, 72, 188, 105, 154, 40, 148, 172, 200, 17, 135, 144, 146, 114, 143, 164, 96, 61, 34, 24, 141, 36, 44, 124, 112, 58, 99, 110, 39, 82, 171, 149, 69, 78, 59, 189, 83, 102, 37, 25, 111, 140, 2, 87, 92, 163, 91, 97, 22, 47, 28, 27, 104, 76, 4, 145, 166, 126, 10, 168, 169, 67, 170, 14, 175, 12, 1, 23, 108, 151, 64, 50, 57, 51, 46, 119, 90, 41, 31, 191, 38, 186, 98, 49, 138, 183, 130, 117, 150, 180, 121, 9, 128, 93, 88, 95, 115, 13, 167, 198, 122, 107, 156, 60, 66, 5, 56, 113, 127, 71, 157, 8, 196, 73, 199, 21, 133, 195, 68, 131, 94, 109, 35, 33, 62, 53, 120, 84, 129, 26, 136, 29, 19, 162, 185, 11, 48, 74, 139, 100, 106, 32, 63, 160, 184, 118, 103, 174, 70, 152, 43, 192, 193, 20, 178, 158, 15, 79, 89, 3, 173, 75, 147, 81, 101, 134, 85)
ihold <- c(245, 21, 91, 233, 157, 127, 114, 243, 31, 224, 176, 59, 260, 6, 71, 50, 328, 312, 330, 44, 188, 234, 7, 64, 85, 144, 246, 299, 39, 317, 97, 283, 49, 229, 72, 221, 78, 154, 265, 226, 102, 76, 303, 286, 41, 5, 20, 266, 104, 252, 112, 3, 290, 82, 40, 11, 321, 320, 193, 181, 29, 151, 137, 238, 153, 93, 190, 306, 145, 217, 89, 268, 186, 220, 32, 201, 125, 123, 302, 22, 86, 199, 118, 171, 45, 43, 133, 70, 269, 184, 203, 274, 323, 161, 219, 291, 73, 175, 51, 284, 267, 263, 168, 14, 332, 293, 53, 272, 54, 63, 126, 159, 83, 84, 327, 131, 249, 109, 198, 18, 183, 208, 202, 121, 15, 227, 288, 156, 129, 26, 142, 182, 322, 23, 250, 163, 259, 140, 200, 210, 47, 270, 106, 158, 285, 19, 139, 209, 61, 240, 101, 24, 81, 130, 79, 275, 197, 92, 1, 213, 146, 307, 324, 315, 122, 136, 165, 107, 258, 257, 77, 230, 80, 225, 60, 108, 33, 174, 180, 308, 124, 75, 35, 271, 46, 48, 111, 143, 119, 273, 2, 326, 206, 331, 277, 189, 100, 169, 287, 55)
library(MASS)
data(Pima.tr)
mytrain=Pima.tr[itrain,] #train data
data(Pima.te)
myhold=Pima.te[ihold,] #hold data
# Fit logistic regression model with all 7 explanatory variables
model1 <- glm(type ~ npreg + glu + bp + skin + bmi + ped + age, data = mytrain, family = "binomial")
# Fit logistic regression model with 4 explanatory variables
model2 <- glm(type ~ glu + bmi + ped + age, data = mytrain, family = "binomial")
# Apply models to holdout dataset and get predicted probabilities
myhold$pred_prob_model1 <- predict(model1, newdata = myhold, type = "response")
myhold$pred_prob_model2 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on predicted probabilities
myhold$pred_class_model1 <- ifelse(myhold$pred_prob_model1 >= 0.5, "Yes", "No")
myhold$pred_class_model2 <- ifelse(myhold$pred_prob_model2 >= 0.5, "Yes", "No")
# Get total number of misclassifications for model 1
misclassifications_model1 <- sum(myhold$diabetes != myhold$pred_class_model1)
cat("Number of misclassifications for model 1:", misclassifications_model1, "\n")
# Get total number of misclassifications for model 2
misclassifications_model2 <- sum(myhold$diabetes != myhold$pred_class_model2)
cat("Number of misclassifications for model 2:", misclassifications_model2, "\n")
# Classify cases based on predicted probabilities with threshold of 0.3
myhold$pred_class_model1_03 <- ifelse(myhold$pred_prob_model1 >= 0.3, "Yes", "No")
myhold$pred_class_model2_03 <- ifelse(myhold$pred_prob_model2 >= 0.3, "Yes", "No")
# Get confusion matrices for both models with threshold of 0.3
table(myhold$pred_class_model1_03, myhold$type)
table(myhold$pred_class_model2_03, myhold$type)
#Part a)
#For model 1, the regression coefficient for ped is
coef(model1)["ped"]
#Part b)
#For model 2, the regression coefficient for age is
coef(model2)
#Part c)
#For the first subject in the holdout set, the predicted probability is:
# __ for model 1,
# __ for model 2.
# For model 1
prob1 <- predict(model1, myhold[1,], type = "response")
prob1
# For model 2
prob2 <- predict(model2, myhold[1,], type = "response")
prob2
#Use a boundary of 0.5 in the predicted probabilities to decide on diabetes (predicted probability greater than or equal to 0.5) or non-diabetes. The total number of misclassifications of the 200 cases in the holdout set is:
# __ for model 1,
# __ for model 2.
# Get predicted probabilities for holdout set using model 1
pred_prob_model1 <- predict(model1, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model1 <- ifelse(pred_prob_model1 >= 0.5, "Yes", "No")
# Get actual classes for holdout set
actual_class <- myhold$type
# Calculate misclassification rate
misclass_rate_model1 <- mean(pred_class_model1 != actual_class)
misclass_rate_model1
# Get number of misclassifications
misclassifications_model1 <- sum(pred_class_model1 != actual_class)
misclassifications_model1
# Get predicted probabilities for holdout set using model 2
pred_prob_model2 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model2 <- ifelse(pred_prob_model2 >= 0.5, "Yes", "No")
# Calculate misclassification rate
misclass_rate_model2 <- mean(pred_class_model2 != actual_class)
misclass_rate_model2
# Get number of misclassifications
misclassifications_model2 <- sum(pred_class_model2 != actual_class)
misclassifications_model2
#Use a boundary of 0.5 in the predicted probabilities to decide on diabetes (predicted probability greater than or equal to 0.5) or non-diabetes. The total number of misclassifications of the 200 cases in the holdout set is:
# __ for model 1,
# __ for model 2.
# Get predicted probabilities for holdout set using model 1
pred_prob_model1 <- predict(model1, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model1 <- ifelse(pred_prob_model1 >= 0.5, "Yes", "No")
# Get actual classes for holdout set
actual_class <- myhold$type
# Calculate misclassification rate
misclass_rate_model1 <- mean(pred_class_model1 != actual_class)
misclass_rate_model1
# Get number of misclassifications
misclassifications_model1 <- sum(pred_class_model1 != actual_class)
misclassifications_model1
# Get predicted probabilities for holdout set using model 2
pred_prob_model2 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model2 <- ifelse(pred_prob_model2 >= 0.5, "Yes", "No")
# Calculate misclassification rate
misclass_rate_model2 <- mean(pred_class_model2 != actual_class)
misclass_rate_model2
# Get number of misclassifications
misclassifications_model2 <- sum(pred_class_model2 != actual_class)
misclassifications_model2
knitr::opts_chunk$set(echo = TRUE)
itrain <- c(187, 116, 125, 80, 72, 188, 105, 154, 40, 148, 172, 200, 17, 135, 144, 146, 114, 143, 164, 96, 61, 34, 24, 141, 36, 44, 124, 112, 58, 99, 110, 39, 82, 171, 149, 69, 78, 59, 189, 83, 102, 37, 25, 111, 140, 2, 87, 92, 163, 91, 97, 22, 47, 28, 27, 104, 76, 4, 145, 166, 126, 10, 168, 169, 67, 170, 14, 175, 12, 1, 23, 108, 151, 64, 50, 57, 51, 46, 119, 90, 41, 31, 191, 38, 186, 98, 49, 138, 183, 130, 117, 150, 180, 121, 9, 128, 93, 88, 95, 115, 13, 167, 198, 122, 107, 156, 60, 66, 5, 56, 113, 127, 71, 157, 8, 196, 73, 199, 21, 133, 195, 68, 131, 94, 109, 35, 33, 62, 53, 120, 84, 129, 26, 136, 29, 19, 162, 185, 11, 48, 74, 139, 100, 106, 32, 63, 160, 184, 118, 103, 174, 70, 152, 43, 192, 193, 20, 178, 158, 15, 79, 89, 3, 173, 75, 147, 81, 101, 134, 85)
ihold <- c(245, 21, 91, 233, 157, 127, 114, 243, 31, 224, 176, 59, 260, 6, 71, 50, 328, 312, 330, 44, 188, 234, 7, 64, 85, 144, 246, 299, 39, 317, 97, 283, 49, 229, 72, 221, 78, 154, 265, 226, 102, 76, 303, 286, 41, 5, 20, 266, 104, 252, 112, 3, 290, 82, 40, 11, 321, 320, 193, 181, 29, 151, 137, 238, 153, 93, 190, 306, 145, 217, 89, 268, 186, 220, 32, 201, 125, 123, 302, 22, 86, 199, 118, 171, 45, 43, 133, 70, 269, 184, 203, 274, 323, 161, 219, 291, 73, 175, 51, 284, 267, 263, 168, 14, 332, 293, 53, 272, 54, 63, 126, 159, 83, 84, 327, 131, 249, 109, 198, 18, 183, 208, 202, 121, 15, 227, 288, 156, 129, 26, 142, 182, 322, 23, 250, 163, 259, 140, 200, 210, 47, 270, 106, 158, 285, 19, 139, 209, 61, 240, 101, 24, 81, 130, 79, 275, 197, 92, 1, 213, 146, 307, 324, 315, 122, 136, 165, 107, 258, 257, 77, 230, 80, 225, 60, 108, 33, 174, 180, 308, 124, 75, 35, 271, 46, 48, 111, 143, 119, 273, 2, 326, 206, 331, 277, 189, 100, 169, 287, 55)
library(MASS)
data(Pima.tr)
mytrain=Pima.tr[itrain,] #train data
data(Pima.te)
myhold=Pima.te[ihold,] #hold data
# Fit logistic regression model with all 7 explanatory variables
model1 <- glm(type ~ npreg + glu + bp + skin + bmi + ped + age, data = mytrain, family = "binomial")
# Fit logistic regression model with 4 explanatory variables
model2 <- glm(type ~ glu + bmi + ped + age, data = mytrain, family = "binomial")
# Apply models to holdout dataset and get predicted probabilities
myhold$pred_prob_model1 <- predict(model1, newdata = myhold, type = "response")
myhold$pred_prob_model2 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on predicted probabilities
myhold$pred_class_model1 <- ifelse(myhold$pred_prob_model1 >= 0.5, "Yes", "No")
myhold$pred_class_model2 <- ifelse(myhold$pred_prob_model2 >= 0.5, "Yes", "No")
# Get total number of misclassifications for model 1
misclassifications_model1 <- sum(myhold$diabetes != myhold$pred_class_model1)
cat("Number of misclassifications for model 1:", misclassifications_model1, "\n")
# Get total number of misclassifications for model 2
misclassifications_model2 <- sum(myhold$diabetes != myhold$pred_class_model2)
cat("Number of misclassifications for model 2:", misclassifications_model2, "\n")
# Classify cases based on predicted probabilities with threshold of 0.3
myhold$pred_class_model1_03 <- ifelse(myhold$pred_prob_model1 >= 0.3, "Yes", "No")
myhold$pred_class_model2_03 <- ifelse(myhold$pred_prob_model2 >= 0.3, "Yes", "No")
# Get confusion matrices for both models with threshold of 0.3
table(myhold$pred_class_model1_03, myhold$type)
table(myhold$pred_class_model2_03, myhold$type)
#Part a)
#For model 1, the regression coefficient for ped is
coef(model1)["ped"]
#Part b)
#For model 2, the regression coefficient for age is
coef(model2)
#Part c)
#For the first subject in the holdout set, the predicted probability is:
# __ for model 1,
# __ for model 2.
# For model 1
prob1 <- predict(model1, myhold[1,], type = "response")
prob1
# For model 2
prob2 <- predict(model2, myhold[1,], type = "response")
prob2
knitr::opts_chunk$set(echo = TRUE)
itrain <- c(187, 116, 125, 80, 72, 188, 105, 154, 40, 148, 172, 200, 17, 135, 144, 146, 114, 143, 164, 96, 61, 34, 24, 141, 36, 44, 124, 112, 58, 99, 110, 39, 82, 171, 149, 69, 78, 59, 189, 83, 102, 37, 25, 111, 140, 2, 87, 92, 163, 91, 97, 22, 47, 28, 27, 104, 76, 4, 145, 166, 126, 10, 168, 169, 67, 170, 14, 175, 12, 1, 23, 108, 151, 64, 50, 57, 51, 46, 119, 90, 41, 31, 191, 38, 186, 98, 49, 138, 183, 130, 117, 150, 180, 121, 9, 128, 93, 88, 95, 115, 13, 167, 198, 122, 107, 156, 60, 66, 5, 56, 113, 127, 71, 157, 8, 196, 73, 199, 21, 133, 195, 68, 131, 94, 109, 35, 33, 62, 53, 120, 84, 129, 26, 136, 29, 19, 162, 185, 11, 48, 74, 139, 100, 106, 32, 63, 160, 184, 118, 103, 174, 70, 152, 43, 192, 193, 20, 178, 158, 15, 79, 89, 3, 173, 75, 147, 81, 101, 134, 85)
ihold <- c(245, 21, 91, 233, 157, 127, 114, 243, 31, 224, 176, 59, 260, 6, 71, 50, 328, 312, 330, 44, 188, 234, 7, 64, 85, 144, 246, 299, 39, 317, 97, 283, 49, 229, 72, 221, 78, 154, 265, 226, 102, 76, 303, 286, 41, 5, 20, 266, 104, 252, 112, 3, 290, 82, 40, 11, 321, 320, 193, 181, 29, 151, 137, 238, 153, 93, 190, 306, 145, 217, 89, 268, 186, 220, 32, 201, 125, 123, 302, 22, 86, 199, 118, 171, 45, 43, 133, 70, 269, 184, 203, 274, 323, 161, 219, 291, 73, 175, 51, 284, 267, 263, 168, 14, 332, 293, 53, 272, 54, 63, 126, 159, 83, 84, 327, 131, 249, 109, 198, 18, 183, 208, 202, 121, 15, 227, 288, 156, 129, 26, 142, 182, 322, 23, 250, 163, 259, 140, 200, 210, 47, 270, 106, 158, 285, 19, 139, 209, 61, 240, 101, 24, 81, 130, 79, 275, 197, 92, 1, 213, 146, 307, 324, 315, 122, 136, 165, 107, 258, 257, 77, 230, 80, 225, 60, 108, 33, 174, 180, 308, 124, 75, 35, 271, 46, 48, 111, 143, 119, 273, 2, 326, 206, 331, 277, 189, 100, 169, 287, 55)
library(MASS)
data(Pima.tr)
mytrain=Pima.tr[itrain,] #train data
data(Pima.te)
myhold=Pima.te[ihold,] #hold data
# Fit logistic regression model with all 7 explanatory variables
model1 <- glm(type ~ npreg + glu + bp + skin + bmi + ped + age, data = mytrain, family = "binomial")
# Fit logistic regression model with 4 explanatory variables
model2 <- glm(type ~ glu + bmi + ped + age, data = mytrain, family = "binomial")
# Apply models to holdout dataset and get predicted probabilities
myhold$pred_prob_model1 <- predict(model1, newdata = myhold, type = "response")
myhold$pred_prob_model2 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on predicted probabilities
myhold$pred_class_model1 <- ifelse(myhold$pred_prob_model1 >= 0.5, "Yes", "No")
myhold$pred_class_model2 <- ifelse(myhold$pred_prob_model2 >= 0.5, "Yes", "No")
# Get total number of misclassifications for model 1
misclassifications_model1 <- sum(myhold$diabetes != myhold$pred_class_model1)
cat("Number of misclassifications for model 1:", misclassifications_model1, "\n")
# Get total number of misclassifications for model 2
misclassifications_model2 <- sum(myhold$diabetes != myhold$pred_class_model2)
cat("Number of misclassifications for model 2:", misclassifications_model2, "\n")
# Classify cases based on predicted probabilities with threshold of 0.3
myhold$pred_class_model1_03 <- ifelse(myhold$pred_prob_model1 >= 0.3, "Yes", "No")
myhold$pred_class_model2_03 <- ifelse(myhold$pred_prob_model2 >= 0.3, "Yes", "No")
# Get confusion matrices for both models with threshold of 0.3
table(myhold$pred_class_model1_03, myhold$type)
table(myhold$pred_class_model2_03, myhold$type)
#Part a)
#For model 1, the regression coefficient for ped is
coef(model1)["ped"]
#Part b)
#For model 2, the regression coefficient for age is
coef(model2)
#Part c)
#For the first subject in the holdout set, the predicted probability is:
# __ for model 1,
# __ for model 2.
# For model 1
prob1 <- predict(model1, myhold[1,], type = "response")
prob1
# For model 2
prob2 <- predict(model2, myhold[1,], type = "response")
prob2
#Use a boundary of 0.5 in the predicted probabilities to decide on diabetes (predicted probability greater than or equal to 0.5) or non-diabetes. The total number of misclassifications of the 200 cases in the holdout set is:
# __ for model 1,
# __ for model 2.
# Get predicted probabilities for holdout set using model 1
pred_prob_model1 <- predict(model1, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model1 <- ifelse(pred_prob_model1 >= 0.5, "Yes", "No")
# Get actual classes for holdout set
actual_class <- myhold$type
# Calculate misclassification rate
misclass_rate_model1 <- mean(pred_class_model1 != actual_class)
misclass_rate_model1
# Get number of misclassifications
misclassifications_model1 <- sum(pred_class_model1 != actual_class)
misclassifications_model1
# Get predicted probabilities for holdout set using model 2
pred_prob_model2 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model2 <- ifelse(pred_prob_model2 >= 0.5, "Yes", "No")
# Calculate misclassification rate
misclass_rate_model2 <- mean(pred_class_model2 != actual_class)
misclass_rate_model2
# Get number of misclassifications
misclassifications_model2 <- sum(pred_class_model2 != actual_class)
misclassifications_model2
#Part f)
#Use a boundary of 0.3 in the predicted probabilities to decide on diabetes (predicted probability greater than or equal to 0.3) or non-diabetes. The total number of misclassifications of the 200 cases in the holdout set is:
# __ for model 1,
# __ for model 2.
# Get predicted probabilities for holdout set using model 1
pred_prob_model1_03 <- predict(model1, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model1_03 <- ifelse(pred_prob_model1_03 >= 0.3, "Yes", "No")
# Get actual classes for holdout set
actual_class_03 <- myhold$type
# Calculate misclassification rate
misclass_rate_model1_03 <- mean(pred_class_model1_03 != actual_class)
misclass_rate_model1_03
# Get number of misclassifications
misclassifications_model1_03 <- sum(pred_class_model1_03 != actual_class)
misclassifications_model1_03
# Get predicted probabilities for holdout set using model 2
pred_prob_model2_03 <- predict(model2, newdata = myhold, type = "response")
# Classify cases based on threshold of 0.5
pred_class_model2_03 <- ifelse(pred_prob_model2_03 >= 0.3, "Yes", "No")
# Calculate misclassification rate
misclass_rate_model2_03 <- mean(pred_class_model2_03 != actual_class)
misclass_rate_model2_03
# Get number of misclassifications
misclassifications_model2_03 <- sum(pred_class_model2_03 != actual_class)
misclassifications_model2_03
knitr::opts_chunk$set(echo = TRUE)
dataq1<-read.csv("advertising.csv")
head(dataq1,5)
class(dataq1$Day)
class(dataq1$Section)
dataq1$Day <- factor(dataq1$Day,levels = c("Monday","Tuesday","Wednesday","Thursday","Friday"))
dataq1$Section <- factor(dataq1$Section,levels = c("Monday","Tuesday","Wednesday","Thursday","Friday"))
class(dataq1$Day)
class(dataq1$Section)
model_q1 <- lm(Inquiries ~ Day + Section, data = dataq1)
dataq1<-read.csv("advertising.csv")
head(dataq1,5)
dataq1<-read.csv("advertising.csv")
head(dataq1,5)
class(dataq1$Day)
class(dataq1$Section)
dataq1$Day <- factor(dataq1$Day,levels = c("Monday","Tuesday","Wednesday","Thursday","Friday"))
dataq1$Section <- factor(dataq1$Section,levels = c("News","Business","Sports"))
class(dataq1$Day)
class(dataq1$Section)
model_q1 <- lm(Inquiries ~ Day + Section, data = dataq1)
plot(model_q1, which = 2)
shapiro.test(model_q1$residuals)
plot(model_q1,which=1)
library(car)
leveneTest(lm(Inquiries ~ Day * Section, data = dataq1))
library(car)
leveneTest(lm(Inquiries ~ Day + Section, data = dataq1))
summary(aov(model_q1))
model_q1b<-lm(Inquiries ~ Day, data = dataq1)
coef(model_q1b)
# Load the necessary package
library(ggplot2)
# Create the interaction plot
interaction.plot(x.factor = dataq1$Day,
trace.factor = dataq1$Section,
response = dataq1$Inquiries,
type = "b",
legend = TRUE,
xlab = "Day",
ylab = "Inquiries",
main = "Interaction Plot of Day and Section on Inquiries")
library(emmeans)
emmeans(model_q1, specs = ~ Day * Section)
dataq1<-read.csv("advertising.csv")
head(dataq1,5)
class(dataq1$Day)
class(dataq1$Section)
dataq1$Day <- factor(dataq1$Day,levels = c("Monday","Tuesday","Wednesday","Thursday","Friday"))
dataq1$Section <- factor(dataq1$Section,levels = c("News","Business","Sports"))
class(dataq1$Day)
class(dataq1$Section)
model_q1 <- lm(Inquiries ~ Day + Section, data = dataq1)
plot(model_q1, which = 2)
shapiro.test(model_q1$residuals)
plot(model_q1,which=1)
summary(aov(model_q1))
model_q1b<-lm(Inquiries ~ Day, data = dataq1)
coef(model_q1b)
dataq1<-read.csv("advertising.csv")
head(dataq1,5)
dataq1<-read.csv("advertising.csv")
head(dataq1,5)
class(dataq1$Day)
class(dataq1$Section)
dataq1$Day <- factor(dataq1$Day,levels = c("Monday","Tuesday","Wednesday","Thursday","Friday"))
dataq1$Section <- factor(dataq1$Section,levels = c("News","Business","Sports"))
class(dataq1$Day)
class(dataq1$Section)
model_q1 <- lm(Inquiries ~ Day * Section, data = dataq1)
model_q2 <- lm(Inquiries ~ Day * Section, data = dataq1)
plot(model_q2, which = 2)
shapiro.test(model_q2$residuals)
plot(model_q2,which=1)
leveneTest(lm(Inquiries ~ Day + Section, data = dataq1))
leveneTest(lm(Inquiries ~ Day * Section, data = dataq1))
summary(aov(model_q2))
library(emmeans)
emmeans(model_q1, specs = ~ Day * Section)
library(emmeans)
emmeans(model_q1, specs = ~ Day * Section)
data_q2<-read.csv("leisure.csv")
head(data_q2,5)
model_q2a<-lm(gdp~hours,data=data_q2)
model_q2a<-lm(gdp~hours,data=data_q2)
model_q2a
model_q2a<-lm(gdp~hours,data=data_q2)
plot(model_q2a, which = 2)
shapiro.test(model_q2a$residuals)
plot(model_q2a,which=1)
leveneTest(lm(gdp~hours,data=data_q2), data = data_q2))
leveneTest(lm(gdp~hours,data=data_q2), data = data_q2)
data_q2<-read.csv("leisure.csv")
head(data_q2,5)
model_q2a<-lm(gdp~hours,data=data_q2)
plot(model_q2a, which = 2)
shapiro.test(model_q2a$residuals)
plot(model_q2a,which=1)
leveneTest(model_q2a)
leveneTest(lm(gdp~hours), data = data_q2)
leveneTest(lm(gdp~hours,data=data_q2)
leveneTest(lm(gdp~hours,data=data_q2))
library(ggplot2)
ggplot(data_q2, aes(x = hours, y = gdp)) +
geom_boxplot()
boxplot(model_q2a$residuals)
summary(model_q2a)
model_q2a$coefficients
model_q2a$coefficients
model_q2c<-lm(gdp~hours+I(hours^2),data=data_q2)
plot(model_q2c, which = 2)
shapiro.test(model_q2c$residuals)
plot(model_q2c,which=1)
plot(model_q2c,which=1)
plot(model_q2a,which=1)
summary(model_q2c)
model_q2c$coefficients
plot(x = data_q2$gdp, y = data_q2$hours,
xlab = "GDP", ylab = "Hours",
main = "Scatterplot of GDP vs. Hours with fited models",
pch=16)
predicted_values <- predict(model_q2a,
newdata = data.frame(gdp =
seq(min(data_q2$gdp),
max(data_q2$gdp),
length.out = 100)))
plot(x = data_q2$gdp, y = data_q2$hour,
xlab = "GDP", ylab = "Hours",
main = "Scatterplot of GDP vs. Hours with fited models",
pch=16)
predicted_values <- predict(model_q2a,
newdata = data.frame(gdp =
seq(min(data_q2$gdp),
max(data_q2$gdp),
length.out = 100)))
plot(x = data_q2$gdp, y = data_q2$hours,
xlab = "GDP", ylab = "Hours",
main = "Scatterplot of GDP vs. Hours with fited models",
pch=16)
predicted_values <- predict(model_q2a,
newdata = data.frame(gdp =
seq(min(data_q2$gdp),
max(data_q2$gdp),
length.out = 100)))
plot(x = data_q2$gdp, y = data_q2$hours,
xlab = "GDP", ylab = "Hours",
main = "Scatterplot of GDP vs. Hours with fited models",
pch=16)
predicted_values <- predict(model_q2c,
newdata = data.frame(gdp =
seq(min(data_q2$gdp),
max(data_q2$gdp),
length.out = 100)))
library(ggplot2)
# Plotting the data points
ggplot(data_q2, aes(x = hours, y = gdp)) +
geom_point() +
labs(x = "Hours", y = "GDP") +
ggtitle("Relationship between GDP and Hours")
# Adding linear model line
ggplot(data_q2, aes(x = hours, y = gdp)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "blue") +
labs(x = "Hours", y = "GDP") +
ggtitle("Relationship between GDP and Hours (Linear Model)")
# Adding quadratic model line
ggplot(data_q2, aes(x = hours, y = gdp)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ poly(x, 2, raw = TRUE), se = FALSE, color = "red") +
labs(x = "Hours", y = "GDP") +
ggtitle("Relationship between GDP and Hours (Quadratic Model)")
# Adding both models on same plot
ggplot(data_q2, aes(x = hours, y = gdp)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "blue", aes(linetype = "Linear Model")) +
geom_smooth(method = "lm", formula = y ~ poly(x, 2, raw = TRUE), se = FALSE, color = "red", aes(linetype = "Quadratic Model")) +
labs(x = "Hours", y = "GDP") +
ggtitle("Relationship between GDP and Hours") +
scale_linetype_manual(name = "Model", values = c("dashed", "solid"), guide = guide_legend(override.aes = list(color = c("blue", "red"))))
library(ggplot2)
# Adding both models on same plot
ggplot(data_q2, aes(x = hours, y = gdp)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "blue", aes(linetype = "Linear Model")) +
geom_smooth(method = "lm", formula = y ~ poly(x, 2, raw = TRUE), se = FALSE, color = "red", aes(linetype = "Quadratic Model")) +
labs(x = "Hours", y = "GDP") +
ggtitle("Relationship between GDP and Hours") +
scale_linetype_manual(name = "Model", values = c("dashed", "solid"), guide = guide_legend(override.aes = list(color = c("blue", "red"))))
knitr::opts_chunk$set(echo = TRUE)
summary(model_q2a)
data_q2<-read.csv("leisure.csv")
head(data_q2,5)
model_q2a<-lm(gdp~hours,data=data_q2)
plot(model_q2a, which = 2)
shapiro.test(model_q2a$residuals)
plot(model_q2a,which=1)
summary(model_q2a)
setwd("C:/Users/Aru/Desktop/Assignment Term 1 Trent/Data Analytics with R/Term project/App-1")
shiny::runApp()
